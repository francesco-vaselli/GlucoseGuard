{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GlucoseGuard","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The following pages describe my<sup>1</sup> project for the Statistical and Machine Learning Models for Time Series Analysis PhD Exam.</p> <p>The reliable prediction of glucose levels in diabetes patients remains a pivotal challenge in biomedical engineering and healthcare informatics. Traditional predictive models have often suffered from inaccuracies and an inability to generalize across different physiological characteristics inherent in patient-specific data. The implications of these shortcomings are nontrivial and bear significant ramifications for clinical decision-making. In the following, we start from a reference paper and we try to reproduce and expand the work already done, to achieve accurate and robust time series forecasting for blood sugar levels prediction.</p> <p>The problem is illustrated in the Figure below. We have a series of Blood Glucose Readings at 5 minutes timestamps. We take as input the values of the previous half-hour (\"Sampling Horizon\") and perform a regression on the following half-hour values (\"Prediciton Horizon\"). We can also treat the problem as a classification by looking at where our predictions fall: either above or below the Hypoglicemia threshold (80 mg/dL).</p> <p></p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>We acknowledge the use of the OpenAPS Data Commons dataset, and we would like to publicly thank the authors and the contributors for the effort of gathering so many real-world patient data and making them accessible.</p> <p>We acknowledge the use of the OhioT1DM dataset for comparison with the reference paper, and we thank the University of Ohio for granting us access to the dataset.</p> <p>Part of the codebase is inspired from AccurateBG which is released under MIT license</p>"},{"location":"#literature-reference","title":"Literature reference","text":"<p>The research paper selected as a starting point is \"Deep Transfer Learning and Data Augmentation Improve Glucose Levels Prediction in Type 2 Diabetes Patients\" by Yixiang Deng et al. The paper proposes a state-of-the-art methodology to address longstanding challenges in predicting glucose levels for diabetes patients.</p>"},{"location":"#background-and-significance","title":"Background and Significance","text":"<p>The reliable prediction of glucose levels in diabetes patients remains a pivotal challenge in biomedical engineering and healthcare informatics. Traditional predictive models have often suffered from inaccuracies and an inability to generalize across different physiological characteristics inherent in patient-specific data. The implications of these shortcomings are nontrivial and bear significant ramifications for clinical decision-making.</p>"},{"location":"#methodological-innovations","title":"Methodological Innovations","text":"<p>The research paper introduces a robust approach that deploys deep transfer learning and data augmentation techniques to ameliorate the inherent challenges in existing models. Deep transfer learning allows the model to benefit from pre-trained networks, thereby reducing the need for extensive datasets. Data augmentation, on the other hand, mitigates the challenges posed by data imbalance by generating synthetic data points for under-represented glucose events, such as spikes or drops.</p>"},{"location":"#findings","title":"Findings","text":"<p>The model proposed by Deng et al. has achieved a predictive accuracy exceeding 95%. This high level of accuracy has profound implications for real-time monitoring systems and clinical practices. It offers the potential for more personalized healthcare interventions and significantly reduces the risks associated with erratic glucose levels. Due to the unbalanced nature of the problem, where hypoglycemic events are a fraction of the dataset, other predictive measures become important. In particular, the precision \\(\\frac{TP}{TP+FP}\\) and the sensitivity \\(\\frac{TP}{TP+FN}\\) of the best model proposed in the paper are 67.68% and 59.19%, showing that there is still room for improvement.</p> <ol> <li> <p>Francesco Vaselli, PhD candidate at Scuola Normale Superiore, francesco.vaselli at sns.it\u00a0\u21a9</p> </li> </ol>"},{"location":"attention/","title":"Attention Network","text":""},{"location":"attention/#model-description","title":"Model description","text":"<p>In the realm of sequence-to-sequence tasks, Attention Networks have garnered attention (pun intended) for their ability to focus on specific parts of the input when generating the output, much like how humans pay attention to specific portions of input when performing tasks like reading or listening. This is particularly useful in time-series prediction tasks like CGM data forecasting, where not all past data points are equally informative for predicting future glucose levels. By weighing the importance of different input data points, Attention Networks aim for more accurate and interpretable predictions.</p> <p>The best hyperparameters after optimization are the following:</p> Hyperparameter Value head_size 448 num_heads 1 ff_dim 480 num_transformer_blocks 6 mlp_units [352, 352] mlp_dropout 0.0 dropout 0.0"},{"location":"attention/#more-results","title":"More results","text":"<p>Aside from the scores reported in the overview, we show here the Confusion Matrix and a regression example for our network</p> <p> </p>"},{"location":"baseline_models/","title":"Baseline Models","text":""},{"location":"baseline_models/#models-descriptions","title":"Models descriptions","text":"<p>We implemented two baseline models: a Gaussian Process regressor and a regressor chain of Support Vector Machine regressors. Both classes of models are already quite complex and include several hyperparameters to tune. </p> <ul> <li> <p>Gaussian Processes offer a non-parametric approach to regression, providing not only a point estimate but also a measure of uncertainty. This is particularly useful in healthcare applications like CGM data forecasting, where understanding the uncertainty associated with predictions can have clinical significance. The choice of kernel function in a GP model is crucial as it defines the shape and smoothness of the function that the model will learn.</p> </li> <li> <p>Support Vector Machines are a class of supervised learning models well-suited for classification and regression tasks. In the context of CGM data, SVMs can provide a robust and efficient mechanism for glucose level prediction. The effectiveness of an SVM model largely hinges on the choice of kernel, which determines the decision boundary. The 'RBF' (Radial Basis Function) kernel is often used for non-linear data, making it a good fit for complex physiological data like CGM readings.</p> </li> </ul> <p>For a great in-depth explanation of GP and SVM we refer the reader to the excellent scikit learn Docs.<sup>1</sup> <sup>2</sup></p> <p>While for GP we trained a single model, we trained multiple SVM and took advantage of scikit learn RegressorChain. It consists of a multi-label model that arranges regressions into a chain. Each model makes a prediction in the order specified by the chain using all of the available features provided to the model plus the predictions of models that are earlier in the chain. This can capture some interdependencies between the output variables, if they exist-- in our use case, we expect future BG reading to have non-trivial dependencies from previous ones.</p> <p>Finally, we should also note that, due to the long convergence time of these algorithms, especially the GP one, these baseline models were trained on a subset of the available data. The selected Hyperparameters for the baseline models are as follows:</p>"},{"location":"baseline_models/#gp-hyperparameters","title":"GP Hyperparameters","text":"<p>Hyperparameters for Gaussian Processes</p> <p>The kernel used in our GP model is a composite function, formulated as:</p> \\[  \\text{Kernel}=\\text{Constant}\u00d7\\text{RBF}+\\text{White Noise}  \\] Hyperparameter Best Value Bounds Constant 1.44**2 [0.0001, 5000] RBF 0.535 [0.001, 1000] White Noise 0.00291 [0.00001, 1]"},{"location":"baseline_models/#svm-hyperparameters","title":"SVM Hyperparameters","text":"Hyperparameter Value Kernel RBF C 1.0 Gamma auto"},{"location":"baseline_models/#more-results","title":"More Results","text":"<p>Aside from the scores reported in the overview, we show here the Confusion Matrix and a regression example for our baseline models</p>"},{"location":"baseline_models/#gp","title":"GP","text":""},{"location":"baseline_models/#svm","title":"SVM","text":"<ol> <li> <p>https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process\u00a0\u21a9</p> </li> <li> <p>https://scikit-learn.org/stable/modules/svm.html#svm\u00a0\u21a9</p> </li> </ol>"},{"location":"cnn/","title":"CNN","text":""},{"location":"cnn/#model-description","title":"Model description","text":"<p>Convolutional Neural Networks (CNNs) have been a cornerstone in image recognition tasks but have also found utility in time-series analysis. The main idea behind a CNN is the use of convolutional layers that automatically and adaptively learn spatial hierarchies of features. In the context of CGM data, CNNs can capture spatial (time-adjacent) dependencies in the glucose measurements, making them well-suited for forecasting tasks.</p> <p>The best hyperparameters after optimization are the following:</p> Hyperparameter Value n_conv_layers 3 filters 160 kernel_size 3 activation relu n_dense_layers 2 dense_size 352"},{"location":"cnn/#more-results-and-loss-curves","title":"More results and loss curves","text":"<p>Aside from the scores reported in the overview, we show here the Confusion Matrix and a regression example for our network</p> <p> </p>"},{"location":"codebase/","title":"Codebase","text":""},{"location":"codebase/#overview-of-codebase-architecture-for-patient-data-aggregation-and-preprocessing","title":"Overview of Codebase Architecture for Patient Data Aggregation and Preprocessing","text":"<p>This codebase comprises a sequence of modular components, each fulfilling a specific role in the pipeline of aggregating and preprocessing Continuous Glucose Monitoring System (CGMS) time-series data. The pipeline has been  developed to enhance usability, modularity, and extensibility. Below is a detailed breakdown of each component.</p>"},{"location":"codebase/#configuration-management-via-yaml-files","title":"Configuration Management via YAML Files","text":"<p>The first component is dedicated to the centralized management of various configurations required for data preprocessing and model training. This is accomplished through a YAML file that contains an organized hierarchy of parameters, such as data directory paths, data scaling options, and smoothing parameters. The adoption of an external YAML configuration file not only enhances the ease of management but also allows for a more flexible system configuration.</p>"},{"location":"codebase/#cgmsdataseg-class-data-preprocessing","title":"CGMSDataSeg Class: Data Preprocessing","text":"<p>The second core component is the CGMSDataSeg class, explicitly designed to handle the segmentation and preprocessing of raw CGMS data. The class is equipped with multiple functionalities like data slicing, scaling, and smoothing. It also offers optional data augmentation techniques, including Gaussian noise and MixUp, to improve the robustness of the resulting dataset. The class thus serves as a comprehensive toolkit for turning raw CGMS time-series data into a refined, machine-learning-ready dataset.</p>"},{"location":"codebase/#datareader-utility-data-collection","title":"DataReader Utility: Data Collection.","text":"<p>Our third component is the DataReader utility class, which has been created to efficiently read and parse JSON files containing patient-specific time-series data. The utility converts the raw JSON data into Python lists, thus making it far more manageable and ready for subsequent preprocessing stages. It boasts the capability of not just reading, but also smartly interpreting the data based on specific attributes and time intervals.</p>"},{"location":"codebase/#dataset-aggregator-data-compilation-and-transformation","title":"Dataset Aggregator: Data Compilation and Transformation","text":"<p>The fourth component is a stand-alone script that functions as a dataset aggregator. Leveraging the DataReader and CGMSDataSeg classes, this script successfully merges data from multiple patients based on their unique identifiers. It is engineered to handle multiple JSON files for each patient and gracefully manage such cases. Post-aggregation, the entire dataset is saved as a NumPy array, making it readily accessible for future machine learning applications.</p>"},{"location":"improvements/","title":"Future Improvements","text":""},{"location":"improvements/#possible-improvements-to-current-work","title":"Possible Improvements to Current Work","text":""},{"location":"improvements/#more-inputs-insulin-on-board-activity-reports-carbohydrates-and-food","title":"More Inputs: Insulin on Board, Activity Reports, Carbohydrates and Food...","text":"<ul> <li>Why It's Relevant: Adding additional inputs like insulin on board, activity levels, and dietary intake can provide a more holistic view of the factors affecting glucose levels. This enriched data set could enhance the model's predictive accuracy by accounting for variables that are intrinsically linked to glucose fluctuations.</li> </ul>"},{"location":"improvements/#time-gan-data-augmentation","title":"Time GAN Data Augmentation","text":"<ul> <li>Why It's Relevant: Time-series Generative Adversarial Networks (Time GANs) can simulate realistic, yet synthetic, time-series data. This could be especially valuable for handling imbalances in the dataset, such as under-represented hypoglycemic or hyperglycemic events, thereby improving the model's generalizability.</li> </ul>"},{"location":"improvements/#longer-input-sequences","title":"Longer Input Sequences","text":"<ul> <li>Why It's Relevant: Extending the length of input sequences may capture more nuanced trends and periodicities in glucose levels. This could lead to predictions that are not only more accurate but also more sensitive to long-term physiological changes in an individual patient.</li> </ul>"},{"location":"improvements/#longer-prediction-horizons","title":"Longer Prediction Horizons","text":"<ul> <li>Why It's Relevant: Lengthening the prediction horizon would allow for more advanced planning and intervention. For example, it could give healthcare providers and patients a better chance to preemptively address hyperglycemic or hypoglycemic episodes, thus improving patient outcomes.</li> </ul>"},{"location":"improvements/#three-class-classification-problem","title":"Three Class Classification Problem","text":"<ul> <li>Why It's Relevant: A three-class classification problem (e.g., hypoglycemic, normoglycemic, hyperglycemic) would offer a more nuanced understanding than a binary above-or-below threshold model. It would enable more targeted interventions based on the severity of the glucose level deviations, making the prediction more actionable.</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>Our dataset is composed of multiple .json files per patient. Each patient is identified by a unique ID. In the following sections we describe the steps which we have used to extract the raw data from the files, preprocess it and optionally perform data augmentation.</p> <p>In the end, we have about a hundred patients to build the train dataset, and we leave out 4 patients to experiment with transfer learning. The large amount of patients data means we end up with a rather large dataset (5 million time series) when compared to the reference work. Each time series is composed by 13 points, each 5 minutes apart: 7 inputs and 6 targets. Training is performed on 3 million time series, validation on 300000 and testing on a separate split of 500000. The data comes from different patients and is shuffled before training.</p> <p>We produced several versions of our dataset, with and without data augmentation. You can find more about that in the relevant section.</p>"},{"location":"overview1/","title":"Overview","text":"<p>In this project, TensorFlow serves as the foundational library, offering a flexible ecosystem for building and training machine learning models. To establish a comprehensive understanding of the task at hand\u2014time-series forecasting of CGM data\u2014we initially implemented baseline models like Gaussian Processes and a chain of Support Vector Machines, using other dedicated libraries. These traditional techniques provided us with a preliminary metric baseline against which more sophisticated approaches could be compared.</p> <p>Subsequently, we ventured into the domain of deep learning, employing architectures like Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), and Attention Networks. These models, known for their ability to capture intricate patterns in data, are elaborated in greater detail in the subsequent sections.</p>"},{"location":"overview1/#comparison-of-results","title":"Comparison of Results","text":"<p>To ascertain the efficacy of our models, we compared our results with those from the reference paper using data from the six patients in the 2020 test split of the OhioT1DM dataset.. The key metrics for MAE, RMSE and the binary classification task with a prediction horizon of 30 minutes (Table 1 of Reference Paper) are summarized in the tables below. As our dataset underwent a different normalization process compared to the one used in the reference paper, we extracted the Standard Deviation value directly from the codebase of the reference paper, which was <code>std = 60.565</code> as opposed to our <code>std = 57.941</code>. We then re-scaled our loss values to provide a fair comparison. We report loss scores computed on both the last 30 minute point of the target sequence and the entire 30 minute sequence. </p> Model 30 min point MAE 30 min point RMSE 30 min seq MAE 30 min seq RMSE GP 21.72 37.95 15.68 34.48 SVM Chain 21.25 36.83 14.56 30.12 CNN (Basic) 12.50 17.88 6.54 9.48 RNN (Basic) 12.61 17.99 6.64 9.59 Attention (Basic) 12.58 17.96 6.62 9.57 Ref paper (Best) 13.53 19.08 Bevan et al<sup>1</sup> 14.37 18.23 (18.82a) Metrics GP SVM Chain CNN (Basic) RNN (Basic) Attention (Basic) Ref paper (Best) Bevan et al<sup>1</sup> Accuracy 95.21% 94.80% 96.28% 96.09% 96.22% 95.98% 95.65% F1 67.71% 59.97% 72.24% 70.58% 71.61% 61.72% 57.40% Sensitivity 72.32% 56.19% 69.57% 67.50% 68.64% 59.19% 49.94% Precision 63.64% 64.29% 75.11% 73.95% 74.86% 67.68% 69.00% Specificity 96.92% 97.67% 98.28% 98.22% 98.28% 98.15% 98.61% NPV 97.92% 96.77% 97.74% 97.59% 97.67% 97.55% 96.76% <p>We note that our results surpass those of the reference paper and of other notable works in the field. The performance on the regression task has been improved. More importantly, improvements on Sensitivity, Precision and F1 score are all good indicators that the models are getting better at classifying potentially dangerous hypoglicemic events (the minority class of the dataset). Note that our models are basic versions, not yet optimized with techniques like data augmentation or transfer learning. We expect performance to escalate upon deploying these improvements. The robustness of simple, baseline models such as GP is evident in their consistent high scores in metrics like Sensitivity. We attribute all of this to the high quantity and good quality of training data at our disposal, showing again the key importance of data when working with ML models. </p> <p>However, if instead of evaluating the models on the \\(\\approx 15000\\) BG sequences of the OhioT1DM dataset we evaluate them on an independent split of \\(500000\\) sequences from our test dataset, never seen before during training or validation, results are even better than what we obtained for the previous table:</p> Metrics GP SVM Chain CNN (Basic) RNN (Basic) Attention (Basic) Accuracy 89.89% 84.47% 97.21% 97.44% 97.07% F1 score 71.86% 52.70% 79.46% 80.77% 78.52% Sensitivity 72.32% 48.46% 80.44% 80.16% 75.38% Precision (PPV) 71.40% 57.74% 78.51% 81.39% 81.94% Specificity 93.71% 92.29% 98.85% 98.40% 98.41% NPV 93.97% 89.18% 98.54% 98.53% 98.50% <p>This suggests that our models may have picked up unique features in our dataset, which hampers their generalizability across different data sources. However, these metrics, derived from a dataset 33 times larger than the initial one, may be considered more robust estimates of our models capacities. This warrants further investigation into our models' performance.</p>"},{"location":"overview1/#results-for-data-augmentation","title":"Results for data augmentation","text":"<p>Wishing to improve the performance on the minority class (hypoglicemic events), we re-trained our models on an augmented dataset. We used the MixUp data augmentation strategy with \\(\\alpha = 2\\) and augmented the minority data from \\(400,000\\) to \\(1,200,000\\) events (a procedure we called upsampling). Results on the Ohio test partition for the models trained on this new dataset are reported below:</p> Model 30 min point MAE 30 min point RMSE 30 min seq MAE 30 min seq RMSE CNN (Upsampled) 12.30 17.71 6.43 9.37 RNN (Upsampled) 12.17 17.54 6.36 9.28 Attention (Upsampled) 12.24 17.62 6.41 9.35 Metrics CNN (Upsampled) RNN (Upsampled) Attention (Upsampled) Accuracy 95.44% 95.63% 95.61% F1 score 72.66% 73.22% 73.38% Sensitivity 87.41% (+17%) 86.06% (+19%) 87.20%  (+19%) Precision 62.18%  (-13%) 63.71%  (-10%) 63.34%  (-11%) Specificity 96.04% 96.35% 96.24% NPV 99.03% 98.93% 99.02% <p>The + and - are in comparison with the baseline models performance on the Ohio test dataset. We can see that all the models have encountered the so-called \"Sensitivity-Precision trade off\". Sensitivity measures how well the models identify actual positives, and it improves when we up-sample the minority class. On the other hand, precision gauges the accuracy of the models' positive predictions. When we make the models more eager to predict positives by up-sampling, it sometimes mislabels negatives as positives, thus reducing precision. It's a tug-of-war between catching more true positives (sensitivity) and avoiding false positives (precision). Interestingly, we note a small improvement of the regression loss as well, for all the models.</p> <p>For addressing this trade off, we could implement weighted loss functions that more heavily penalize false positives, helping to increase precision. Another approach is utilizing ensemble methods, combining models that are strong in either sensitivity or precision to achieve a balanced performance. We could also experiment with adjusting the decision threshold for our classifiers; lowering it could increase precision without severely affecting sensitivity. </p>"},{"location":"overview1/#bayesian-hyperparameter-tuning-with-keras","title":"Bayesian Hyperparameter Tuning with Keras","text":"<p>To select the best combination of hyperparameters for each model, we leveraged Keras' BayesianOptimizationOracle for hyperparameter tuning. Unlike traditional methods like grid search or random search, Bayesian optimization provides an intelligent approach to navigating the hyperparameter space. It builds a probabilistic model of the objective function based on past trial data and uses this to predict the most promising hyperparameters to try next. This guided strategy is computationally efficient and often yields more accurate models compared to standard choices.</p> <ol> <li> <p>Bevan, R. &amp; Coenen, F. In (eds Bach, K., Bunescu, R., Marling, C. &amp; Wiratunga, N.) Knowledge Discovery in Healthcare Data 2020, Vol. 2675, 100\u2013104 (CEUR Workshop Proceedings, 2020).\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"preprocessing/","title":"Data Preprocessing","text":""},{"location":"preprocessing/#inaccuracies-in-current-cgm-technologies","title":"Inaccuracies in Current CGM Technologies","text":"<p>Continuous Glucose Monitoring (CGM) technologies have revolutionized the management of diabetes by providing real-time, high-frequency glucose readings. However, these systems are not without their flaws. For example, sensor drift and noise can introduce inconsistencies in the data. Calibration errors can also skew measurements, making it difficult to rely solely on CGM data for clinical decisions. Additionally, factors like temperature, humidity, and body movement can interfere with the sensor's performance. This variability necessitates robust preprocessing steps to improve the reliability of CGM data.</p>"},{"location":"preprocessing/#savitzky-golay-filter-for-data-smoothing","title":"Savitzky-Golay Filter for Data Smoothing","text":"<p>One widely-adopted method to address these inaccuracies is the application of the Savitzky-Golay filter. This polynomial-based smoothing technique is particularly well-suited for time-series data with noise, as it allows for the preservation of high-frequency features while reducing random fluctuations. In essence, it fits a polynomial of a certain degree to a window of adjacent data points, calculating a smoothed value for each point in the series. This proves invaluable for CGM data, where capturing the nuances of glucose changes without the noise is critical for effective forecasting. We applied the filter following the example of our reference paper.</p>"},{"location":"preprocessing/#standardization-of-ml-inputs","title":"Standardization of ML Inputs","text":"<p>Lastly, it is a standard practice in machine learning to normalize the features to bring them onto a similar scale. For this project, the CGM data was preprocessed by subtracting the mean and dividing by the standard deviation. This process, known as z-score normalization or standardization, ensures that the data has zero mean and a standard deviation of one. This normalization enhances the performance and stability of machine learning algorithms, particularly those sensitive to the scale of input features, such as gradient-based models.</p>"},{"location":"rnn/","title":"RNN","text":""},{"location":"rnn/#model-description","title":"Model description","text":"<p>Recurrent Neural Networks (RNNs) excel in handling sequential data, making them a natural fit for time-series forecasting tasks like CGM data prediction. However, vanilla RNNs suffer from vanishing and exploding gradient problems, making it difficult for them to capture long-range dependencies in the data. Enter LSTMs\u2014these specialized units are capable of learning such long-term dependencies by maintaining a \"cell state\" that can be updated and queried as the network processes sequences. This makes LSTMs well-suited for complex time-series tasks where the relationship between past and future points is crucial.</p> <p>The best hyperparameters after optimization are the following:</p> Hyperparameter Value n_rnn_layers 1 rnn_units 224 n_dense_layers 2 dense_size 64"},{"location":"rnn/#more-results","title":"More results","text":"<p>Aside from the scores reported in the overview, we show here the Confusion Matrix and a regression example for our network</p> <p> </p>"},{"location":"upsampling/","title":"Data Augmentation","text":"<p>In the realm of machine learning for healthcare, class imbalance is a recurrent issue. The minority class\u2014here, critical hypoglycemic events\u2014is often underrepresented, which could lead to poor generalization and biased predictions towards the majority class. Augmentation strategies serve as vital countermeasures, enhancing the robustness of the model by artificially inflating the training dataset with synthetic but plausible examples. This is particularly crucial for applications like CGM data forecasting, where overlooking a rare hypoglycemic event could have serious health implications.</p>"},{"location":"upsampling/#augmentation-strategies","title":"Augmentation Strategies","text":""},{"location":"upsampling/#gaussian-noise","title":"Gaussian Noise","text":"<p>To mitigate overfitting and to make the model more resilient to the innate noise in CGM data, Gaussian noise with a mean of 0 and a variance of 3 was added solely to the input sequences during training. This technique is predicated on the notion that similar input sequences should yield similar behavior; therefore, small perturbations around a true reading should not dramatically alter the forecast. This injects an element of stochasticity into the model, helping it to generalize better to unseen data.</p>"},{"location":"upsampling/#mixup","title":"MixUp","text":"<p>Originating from the work by Zhang et al<sup>1</sup>, MixUp is an augmentation strategy that has garnered attention for its efficacy in enhancing neural network generalization. The method involves linearly interpolating between samples in the training dataset according to the formula:</p> \\[ \\tilde{x} = \\lambda x_i + (1 - \\lambda) x_j, \\quad \\tilde{y}=\\lambda y_i + (1 - \\lambda) y_j \\] <p>Here, \\(\\lambda\\) is a hyperparameter following the Beta distribution, Beta(\\(\\alpha\\),\\(\\alpha\\)), and \\(x_i\\), \\(x_j\\)\u200b denote inputs from two different samples, respectively. In our application, we constrain MixUp to the minority class, specifically those with \\((x, \\; y)&lt;80\\), to counterbalance the dataset.</p> <p>The hyperparameter \\(\\alpha\\) is a sensitive knob controlling the diversity of synthetic samples. Higher values produce samples more resembling to the reference real data while lower ones introduce samples very different from the reference real data.  The reference work examined \\(\\alpha = 0.4\\) and \\(\\alpha = 2\\) in twofold MixUp and found improvements in both positive predictive value (PPV) and sensitivity for the minority class across various prediction horizons. We employed \\(\\alpha = 2\\).</p> <ol> <li> <p>https://arxiv.org/abs/1710.09412\u00a0\u21a9</p> </li> </ol>"}]}