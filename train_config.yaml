data_path: "./data/dataset.npy"
n_train: 2000000
n_val: 300000
n_test: 500000
batch_size: 256
buffer_size: 1000 # not used
epochs: 200
optimizer: "adam"
loss: "mae"
learning_rate: 0.01
model_config:
  model_type: "attn"
  cnn_config:
    n_conv_layers: 2
    filters: 64
    kernel_size: 3
    activation: "relu"
    input_shape: [7, 1]
    n_dense_layers: 3
    dense_size: 64
    output_shape: 6
  rnn_config:
    n_rnn_layers: 2
    rnn_units: 64
    n_dense_layers: 3
    dense_size: 64
    output_shape: 6
    input_shape: [7, 1]
  ar_rnn_config:
    units: 1
    unit_size: 64
    out_steps: 6
    num_features: 1
    dense_size: 64
    dense_units: 3
  attn_config:
    input_shape: [7, 1],
    output_shape: 6,
    head_size: 256,
    num_heads: 4,
    ff_dim: 4,
    num_transformer_blocks: 4,
    mlp_units: [128],
    mlp_dropout: 0.4,
    dropout: 0.25,
